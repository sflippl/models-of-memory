{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e92e1a",
   "metadata": {},
   "source": [
    "# Memory tasks for LLMs\n",
    "Authors: Chris Iyer, Sam Lippl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896076c",
   "metadata": {},
   "source": [
    "combining all tasks into one notebook for smoother model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7fbabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisiyer/miniconda3/envs/dl/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    }
   ],
   "source": [
    "import sys, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# for running on colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    !git clone https://github.com/sflippl/models-of-memory.git\n",
    "    sys.path.append('models-of-memory')\n",
    "    dir = 'models-of-memory'\n",
    "else:\n",
    "    print(\"Running locally\")\n",
    "    dir = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8c3215",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Shared helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91894481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_list(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = [line.strip().lower() for line in f.readlines()]\n",
    "    return lines\n",
    "\n",
    "\n",
    "def subsample_words(words, n, seed=None, avoid=[]):\n",
    "    \"\"\"\n",
    "    Return a random subset of n unique words from the list.\n",
    "    Optionally set a random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    if n > len(words):\n",
    "        raise ValueError(\"Sample size cannot exceed number of words.\")\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    if len(avoid) > 0:\n",
    "        words = [w for w in words if w not in avoid]\n",
    "    return random.sample(words, n)\n",
    "\n",
    "\n",
    "def make_pairs(first_words, second_words, joiner='-', randomize=False):\n",
    "    # \"chair-apple\"\n",
    "    np.random.seed(0)\n",
    "    rand_draws = np.random.rand(len(first_words))\n",
    "    pairs = []\n",
    "    for first, second, rand in zip(first_words, second_words, rand_draws):\n",
    "        if randomize and rand < 0.5:\n",
    "            first, second = second, first\n",
    "        pairs.append(f'{first}{joiner}{second}')\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def make_test_probes(cue_words, target_words, lure_words):\n",
    "    # for paired associate tests: 2-alternative-forced-choice tests\n",
    "    np.random.seed(0)\n",
    "    perm = np.random.permutation(len(cue_words))\n",
    "    cue_words = np.array(cue_words)[perm]\n",
    "    target_words = np.array(target_words)[perm]\n",
    "    lure_words = np.array(lure_words)[perm]\n",
    "    out = []\n",
    "    rand_draw = np.random.rand(len(cue_words))\n",
    "    for i,(c,t,l) in enumerate(zip(cue_words, target_words, lure_words)):\n",
    "        if rand_draw[i] < 0.5:\n",
    "            out.append(f'{c}: {t} or {l}?')\n",
    "        else:\n",
    "            out.append(f'{c}: {l} or {t}?')\n",
    "    return out, list(target_words), list(lure_words)\n",
    "\n",
    "\n",
    "def make_training_order(first_pairs, second_pairs, unrelated_pairs=[]):\n",
    "    # for paired associate inference nad acquired equivalence\n",
    "    # AB[i] must come before BC[i], but DE can come anywhere\n",
    "    all_items = first_pairs + second_pairs + unrelated_pairs\n",
    "    random.seed(0)\n",
    "    random.shuffle(all_items)\n",
    "    # now loop through random list and replace any BC that are before their AB pair\n",
    "    for i, (first, second) in enumerate(zip(first_pairs, second_pairs)):\n",
    "        first_idx = all_items.index(first)\n",
    "        second_idx = all_items.index(second)\n",
    "        if second_idx < first_idx:\n",
    "            # remove second and reinsert it after first at a random later position\n",
    "            all_items.pop(second_idx)\n",
    "            first_idx = all_items.index(first)\n",
    "            insert_pos = random.randint(first_idx + 1, len(all_items))\n",
    "            all_items.insert(insert_pos, second)\n",
    "    return all_items\n",
    "\n",
    "\n",
    "def is_derangement(original_list, permuted_list):\n",
    "    \"\"\"Checks if a permuted list is a derangement of the original list.\"\"\"\n",
    "    for i in range(len(original_list)):\n",
    "        if original_list[i] == permuted_list[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def generate_derangement(input_list):\n",
    "    \"\"\"Generates a random derangement (permutation but all entries are changed) of the input list.\"\"\"\n",
    "    random.seed(0)\n",
    "    temp_list = list(input_list) # Create a copy to avoid modifying the original\n",
    "    while True:\n",
    "        random.shuffle(temp_list)\n",
    "        if is_derangement(input_list, temp_list):\n",
    "            return temp_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27157c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inp(words, test_words=[], preamble='', cue='', interjection=None, interjection_words=[]):\n",
    "    inp = f'{preamble} {\", \".join(words)}. '\n",
    "    if interjection:\n",
    "        inp += f'{interjection} {\", \".join(interjection_words)}. '\n",
    "    inp += cue\n",
    "    if len(test_words) > 0:\n",
    "        inp += \", \".join(test_words)\n",
    "    return inp\n",
    "\n",
    "\n",
    "def make_pipe(model_id):\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def query_model_helper(pipe, inp):\n",
    "    messages = [\n",
    "    {\"role\": \"user\", \"content\": inp},\n",
    "    ]\n",
    "    outputs = pipe(\n",
    "        messages,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.7,\n",
    "        top_p=0.8,\n",
    "        top_k=20,\n",
    "        min_p=0.\n",
    "\n",
    "    )\n",
    "    return outputs\n",
    "\n",
    "def query_model(pipe, inp):\n",
    "    outputs = query_model_helper(pipe, inp)\n",
    "    lst_words = outputs[0][\"generated_text\"][-1]['content'].split('— Wait')[0].split(', ')\n",
    "    lst_words = [w.strip().lower() for w in lst_words]\n",
    "    return lst_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd11a50",
   "metadata": {},
   "source": [
    "# Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0f171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = txt_to_list(f'{dir}/_data/wasnorm_wordpool.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea54805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "pipe = make_pipe(model_id = \"Qwen/Qwen3-4B-Instruct-2507\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad5df3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1. List learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbe27cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_length = 50\n",
    "interjection_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37bb3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_recall_precision(true_list, output_list, interjected_list=[]):\n",
    "    subset_of_words = [w for w in true_list if w[0] in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']]\n",
    "    recall = [w in output_list for w in subset_of_words]\n",
    "    precision = [w in set(subset_of_words) for w in np.unique(output_list)]\n",
    "    ncols = 2\n",
    "    i_bool = len(interjected_list) >0\n",
    "    if i_bool:\n",
    "        precision_int = [w in set(interjected_list) for w in np.unique(output_list)]\n",
    "        ncols = 3\n",
    "    \n",
    "    fig,ax = plt.subplots(1,ncols)\n",
    "    ax[0].plot(recall)\n",
    "    ax[0].set_title('Recall')\n",
    "    ax[0].set_xlabel('Word in true list')\n",
    "    ax[0].set_ylabel('Present in recalled list')\n",
    "\n",
    "    ax[1].plot(precision)\n",
    "    ax[1].set_title('Precision')\n",
    "    ax[1].set_xlabel('Word in output (unique)')\n",
    "    ax[1].set_ylabel('Present in true list')\n",
    "\n",
    "    if i_bool:\n",
    "        ax[2].plot(precision_int)\n",
    "        ax[2].set_title('False alarms to interjections')\n",
    "        ax[2].set_xlabel('Word in output (unique)')\n",
    "        ax[2].set_ylabel('Present in interjection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = subsample_words(all_words, list_length, seed=0)\n",
    "interjection_words = subsample_words(all_words, interjection_length, seed=0, avoid=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "709d9d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of words: knuckle, vehicle, man, bank, employee, perch, ozone, list, whistle, garbage, onion, igloo, roach, deodorant, pearl, cheddar, fleet, cheek, van, bulletin, senate, zucchini, earring, plumber, telephone, sap, chimney, giraffe, butcher, traitor, boss, sugar, hall, oatmeal, quail, button, house, microphone, goo, scout, sister, cub, proton, monastery, pill, enemy, biologist, prince, antler, bulb. Please list all words from the list, in any order you'd like. Do not think step by step, only output the list of words.\n",
      "Here is a list of words: knuckle, vehicle, man, bank, employee, perch, ozone, list, whistle, garbage, onion, igloo, roach, deodorant, pearl, cheddar, fleet, cheek, van, bulletin, senate, zucchini, earring, plumber, telephone, sap, chimney, giraffe, butcher, traitor, boss, sugar, hall, oatmeal, quail, button, house, microphone, goo, scout, sister, cub, proton, monastery, pill, enemy, biologist, prince, antler, bulb. You will now see another list of words. letter, whale, message, banner, face, planet, patrol, magnet, globe, pan, jewel, sardine, dice, pike, chick, fort, chicken, wave, bus, sink, emerald, prison, tower, shark, citizen, grasshopper, cabin, university, boulevard, telescope, heater, pad, reptile, cactus, jam, moss, guardian, shoulder, sponge, cyclone, rattle, mustard, pool, family, bison, railroad, apartment, bunny, turkey, lollipop, treat, surgeon, sleeve, acorn, shower, pendulum, herb, ear, utensil, hare, tote, blackberry, creature, rocket, dinner, drum, chip, quilt, net, building, brandy, hail, pistol, pebble, cannon, girl, rash, fungus, tractor, cavity, rag, hen, puppy, custard, sheep, raft, scapegoat, fries, necklace, bull, seashore, guitar, runner, dustpan, fugitive, country, cradle, coward, bag, shrimp, stove, fairy, palm, body, buggy, tar, well, chairperson, class, bandit, tombstone, purse, teenager, lint, port, florida, popcorn, dresser, detective, tart, school, medal, salmon, floor, nicotine, pen, stump, spoon, tool, jelly, bride, handkerchief, carnival, pavement, scalpel, sneaker, hiker, crayon, dynamite, apron, valley, fist, carriage, dill, knife, concrete, missile, circus, toenail, dictator, basket, rug, sofa, professor, shears, taxi, attic, cave, soldier, cracker, sheriff, rust, cashier, kleenex, carpenter, ballot, shepherd, asia, critic, course, tulip, cauliflower, parent, deer, uncle, bird, assistant, raccoon, mirror, skeleton, cafe, bomb, dime, booth, stake, gift, instructor, motor, corn, pigeon, outdoors, banjo, cucumber, joint, ox, room, compass, switch, worker, bench. Please list all words from the first list you saw, in any order you'd like. Do not output words from the interjecting list. Do not think step by step, only output the list of words.\n",
      "Here is a list of words: knuckle, vehicle, man, bank, employee, perch, ozone, list, whistle, garbage, onion, igloo, roach, deodorant, pearl, cheddar, fleet, cheek, van, bulletin, senate, zucchini, earring, plumber, telephone, sap, chimney, giraffe, butcher, traitor, boss, sugar, hall, oatmeal, quail, button, house, microphone, goo, scout, sister, cub, proton, monastery, pill, enemy, biologist, prince, antler, bulb. Please list all words that start with the letters a,b,c,d,e,f,g,h. List these words in any order you'd like without listing any other words provided in the list. Do not think step by step, only output the list of words.\n",
      "Here is a list of words. After seeing this list, list all the words starting with a,b,c,d,e,f,g,h. Make sure to not reproduce any other words: knuckle, vehicle, man, bank, employee, perch, ozone, list, whistle, garbage, onion, igloo, roach, deodorant, pearl, cheddar, fleet, cheek, van, bulletin, senate, zucchini, earring, plumber, telephone, sap, chimney, giraffe, butcher, traitor, boss, sugar, hall, oatmeal, quail, button, house, microphone, goo, scout, sister, cub, proton, monastery, pill, enemy, biologist, prince, antler, bulb. Please list all words that start with the letters a,b,c,d,e,f,g,h. List these words in any order you'd like without listing any other words provided in the list. Do not think step by step, only output the list of words.\n",
      "Here is a list of words. After seeing this list, list all the words starting with a,b,c,d,e,f,g,h. Make sure to not reproduce any other words: knuckle, vehicle, man, bank, employee, perch, ozone, list, whistle, garbage, onion, igloo, roach, deodorant, pearl, cheddar, fleet, cheek, van, bulletin, senate, zucchini, earring, plumber, telephone, sap, chimney, giraffe, butcher, traitor, boss, sugar, hall, oatmeal, quail, button, house, microphone, goo, scout, sister, cub, proton, monastery, pill, enemy, biologist, prince, antler, bulb. You will now see another list of words. Later, when reproducing the first list of words, you should not reproduce these words: letter, whale, message, banner, face, planet, patrol, magnet, globe, pan, jewel, sardine, dice, pike, chick, fort, chicken, wave, bus, sink, emerald, prison, tower, shark, citizen, grasshopper, cabin, university, boulevard, telescope, heater, pad, reptile, cactus, jam, moss, guardian, shoulder, sponge, cyclone, rattle, mustard, pool, family, bison, railroad, apartment, bunny, turkey, lollipop, treat, surgeon, sleeve, acorn, shower, pendulum, herb, ear, utensil, hare, tote, blackberry, creature, rocket, dinner, drum, chip, quilt, net, building, brandy, hail, pistol, pebble, cannon, girl, rash, fungus, tractor, cavity, rag, hen, puppy, custard, sheep, raft, scapegoat, fries, necklace, bull, seashore, guitar, runner, dustpan, fugitive, country, cradle, coward, bag, shrimp, stove, fairy, palm, body, buggy, tar, well, chairperson, class, bandit, tombstone, purse, teenager, lint, port, florida, popcorn, dresser, detective, tart, school, medal, salmon, floor, nicotine, pen, stump, spoon, tool, jelly, bride, handkerchief, carnival, pavement, scalpel, sneaker, hiker, crayon, dynamite, apron, valley, fist, carriage, dill, knife, concrete, missile, circus, toenail, dictator, basket, rug, sofa, professor, shears, taxi, attic, cave, soldier, cracker, sheriff, rust, cashier, kleenex, carpenter, ballot, shepherd, asia, critic, course, tulip, cauliflower, parent, deer, uncle, bird, assistant, raccoon, mirror, skeleton, cafe, bomb, dime, booth, stake, gift, instructor, motor, corn, pigeon, outdoors, banjo, cucumber, joint, ox, room, compass, switch, worker, bench. Please list the words from the first list you saw, but only the words that start with the letters a,b,c,d,e,f,g,h. List these words in any order you'd like without listing any other words provided in the list, or in the intervening list. Do not think step by step, only output the list of words.\n"
     ]
    }
   ],
   "source": [
    "# example formats of task inputs\n",
    "simple_inp = make_inp(\n",
    "    words,\n",
    "    preamble = \"Here is a list of words:\",\n",
    "    cue = \"Please list all words from the list, in any order you'd like. \" \\\n",
    "        \"Do not think step by step, only output the list of words.\"\n",
    ")\n",
    "print(simple_inp)\n",
    "\n",
    "interjection_inp = make_inp(\n",
    "    words,\n",
    "    preamble = \"Here is a list of words:\",\n",
    "    cue = \"Please list all words from the first list you saw, in any order you'd like. \" \\\n",
    "        \"Do not output words from the interjecting list. \" \\\n",
    "        \"Do not think step by step, only output the list of words.\",\n",
    "    interjection = \"You will now see another list of words.\",\n",
    "    interjection_words = interjection_words,\n",
    ")\n",
    "print(interjection_inp)\n",
    "\n",
    "gated_inp = make_inp(\n",
    "    words,\n",
    "    preamble = \"Here is a list of words:\",\n",
    "    cue = \"Please list all words that start with the letters a,b,c,d,e,f,g,h. \" \\\n",
    "        \"List these words in any order you'd like without listing any other words provided in the list. \" \\\n",
    "        \"Do not think step by step, only output the list of words.\",\n",
    ")\n",
    "print(gated_inp)\n",
    "\n",
    "gated_informed_inp = make_inp(\n",
    "    words,\n",
    "    preamble = \"Here is a list of words. After seeing this list, \" \\\n",
    "        \"list all the words starting with a,b,c,d,e,f,g,h. Make sure to not reproduce any other words:\",\n",
    "    cue = \"Please list all words that start with the letters a,b,c,d,e,f,g,h. \" \\\n",
    "        \"List these words in any order you'd like without listing any other words provided in the list. \" \\\n",
    "        \"Do not think step by step, only output the list of words.\",\n",
    ")\n",
    "print(gated_informed_inp)\n",
    "\n",
    "gated_informed_interjection_inp = make_inp(\n",
    "    words,\n",
    "    preamble = \"Here is a list of words. After seeing this list, \" \\\n",
    "        \"list all the words starting with a,b,c,d,e,f,g,h. Make sure to not reproduce any other words:\",\n",
    "    cue = \"Please list the words from the first list you saw, but only the words that \" \\\n",
    "        \"start with the letters a,b,c,d,e,f,g,h. List these words in any order you'd like without \" \\\n",
    "        \"listing any other words provided in the list, or in the intervening list. \" \\\n",
    "        \"Do not think step by step, only output the list of words.\",\n",
    "    interjection = \"You will now see another list of words. \" \\\n",
    "        \"Later, when reproducing the first list of words, you should not reproduce these words:\",\n",
    "    interjection_words = interjection_words,\n",
    ")\n",
    "print(gated_informed_interjection_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp in [simple_inp, interjection_inp, gated_inp, gated_informed_inp, gated_informed_interjection_inp]:\n",
    "    print(inp)\n",
    "    lst_words = query_model(pipe, inp)\n",
    "    print(lst_words)\n",
    "    plot_recall_precision(words, lst_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401469e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2. List recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccecdeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_length = 50\n",
    "interjection_length = 200\n",
    "include_interjected_in_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fd7a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from scipy.stats import norm\n",
    "\n",
    "def query_model_recognition(pipe, inp):\n",
    "    outputs = query_model_helper(pipe, inp)\n",
    "    lst_words = outputs[0][\"generated_text\"][-1]['content'].split('— Wait')[0].split(', ')\n",
    "    lst_words = [w.strip().lower() for w in lst_words] # 'yes'/'no'\n",
    "    lst_words = [w.translate(str.maketrans('', '', string.punctuation)) for w in lst_words]\n",
    "    if 'yes' not in lst_words or 'no' not in lst_words or len(np.unique(lst_words)) > 2:\n",
    "        raise(\"ERROR - unexpected output: \", lst_words)\n",
    "    lst_binary = [int(w=='yes') for w in lst_words]\n",
    "    return lst_binary\n",
    "\n",
    "def plot_results(true, resp):\n",
    "    true = np.array(true)\n",
    "    resp = np.array(resp)\n",
    "    hit_rate = np.sum((resp) & (true))/np.sum(true)\n",
    "    false_alarm_rate = np.sum((resp) & (true==0))/np.sum(true==0)\n",
    "    d_prime = norm.ppf(hit_rate) - norm.ppf(false_alarm_rate)\n",
    "    x,y,labels = [1,2,3],[hit_rate, false_alarm_rate, d_prime],['hit rate', 'false alarm rate', 'd\\'']\n",
    "\n",
    "    if include_interjected_in_test:\n",
    "        x.extend([4,5])\n",
    "        labels.extend(['false alarm rate on new', 'false alarm rate on interjected'])\n",
    "        y.extend([\n",
    "            (np.sum((true == 0) & (resp))/np.sum(true==0)),\n",
    "            (np.sum((true == 2) & (resp))/np.sum(true==2)),\n",
    "        ])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.suptitle('Recognition test performance')\n",
    "    plt.bar(x,y)\n",
    "    plt.xticks(x, labels=labels, rotation=30)\n",
    "    plt.ylim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = subsample_words(all_words, list_length, seed=0)\n",
    "lures = subsample_words(all_words, list_length, seed=0, avoid=words)\n",
    "interjection_words = subsample_words(all_words, list_length, seed=0, avoid=words+lures)\n",
    "if include_interjected_in_test:\n",
    "    interjection_sample = subsample_words(interjection_words, list_length, seed=0)\n",
    "    combined = [(w, 1) for w in words] + [(l, 0) for l in lures] + [(l, 2) for l in interjection_sample] # new label 2 for interjection\n",
    "else:\n",
    "    combined = [(w, 1) for w in words] + [(l, 0) for l in lures]\n",
    "    \n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(len(combined)) \n",
    "test_words = [combined[i][0] for i in perm]\n",
    "test_labels = [combined[i][1] for i in perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f1db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_inp = make_inp(\n",
    "    words,test_words,\n",
    "    preamble = \"Here is a list of words:\",\n",
    "    cue = \"Now we'll begin the memory test. Here is another list of words, \" \\\n",
    "        \"containing some words from the original list and some new words. \" \\\n",
    "        \"Please output a list of \\\"yes\\\" or \\\"no\\\" corresponding to whether each word was in the original list. \" \\\n",
    "        \"Only output the list of \\\"yes\\\" and \\\"no\\\", nothing else. Here are the test words:\"\n",
    ")\n",
    "print(recognition_inp)\n",
    "\n",
    "recognition_inp_informed = make_inp(\n",
    "    words,test_words,\n",
    "    preamble = \"Here is a list of words. After seeing this list, you will be tested on your memory for words in this list:\",\n",
    "    cue = \"Now we'll begin the memory test. Here is another list of words, containing some words from the original list and some new words. \" \\\n",
    "        \"Please output a list of \\\"yes\\\" or \\\"no\\\" corresponding to whether each word was in the original list. \" \\\n",
    "        \"Only output the list of \\\"yes\\\" and \\\"no\\\", nothing else. Here are the test words:\"\n",
    ")\n",
    "print(recognition_inp_informed)\n",
    "\n",
    "\n",
    "recognition_inp_interjection = make_inp(\n",
    "    words,test_words,\n",
    "    preamble = \"Here is a list of words:\",\n",
    "    cue = \"Now we'll begin the memory test. Here is another list of words, \" \\\n",
    "        \"containing some words from the original list, some from the intervening list, and some new words. \" \\\n",
    "        \"Please output a list of \\\"yes\\\" or \\\"no\\\" corresponding to whether each word was in the ORIGINAL list (not the intervening list). \" \\\n",
    "        \"Only output the list of \\\"yes\\\" and \\\"no\\\", nothing else. Here are the test words: \",\n",
    "    interjection = \"You will now see another list of words:\",\n",
    "    interjection_words = interjection_words,\n",
    ")\n",
    "print(recognition_inp_interjection)\n",
    "\n",
    "\n",
    "recognition_inp_interjection_informed = make_inp(\n",
    "    words, test_words,\n",
    "    preamble = \"Here is a list of words. After seeing this list, you will see another list, \" \\\n",
    "        \"and then a memory test for the words in the original (first) list:\",\n",
    "    cue = \"Now we'll begin the memory test. Here is another list of words, \" \\\n",
    "        \"containing some words from the original list, some from the intervening list, and some new words. \" \\\n",
    "        \"Please output a list of \\\"yes\\\" or \\\"no\\\" corresponding to whether each word was in the ORIGINAL list (not the intervening list). \" \\\n",
    "        \"Only output the list of \\\"yes\\\" and \\\"no\\\", nothing else. Here are the test words:\",\n",
    "    interjection = \"You will now see another list of words. Later, when doing the memory test, \" \\\n",
    "        \"you should not base your responses on the words in this list:\",\n",
    "    interjection_words = interjection_words,\n",
    ")\n",
    "print(recognition_inp_interjection_informed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ec8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp in [recognition_inp, recognition_inp_informed, recognition_inp_interjection, recognition_inp_interjection_informed]:\n",
    "    print(inp)\n",
    "    binary_output = query_model_recognition(pipe, inp)\n",
    "    print(binary_output)\n",
    "    plot_results(test_labels, binary_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627166ff",
   "metadata": {},
   "source": [
    "# 3. Paired associate learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61746340",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_length = 50\n",
    "interjection_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea13da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(true_list, output_list, interjected_list=[], gated=False):\n",
    "    ncols = 2\n",
    "\n",
    "    recall = [w in output_list for w in true_list]\n",
    "    precision = [w in set(true_list) for w in np.unique(output_list)]\n",
    "    if gated:\n",
    "        subset_of_words = [w for w in true_list if w[0] in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']]\n",
    "        recall_gated = [w in output_list for w in subset_of_words]\n",
    "        precision_gated = [w in set(subset_of_words) for w in np.unique(output_list)]\n",
    "        ncols +=2\n",
    "\n",
    "    i_bool = len(interjected_list) >0\n",
    "    if i_bool:\n",
    "        precision_int = [w in set(interjected_list) for w in np.unique(output_list)]\n",
    "        ncols += 1\n",
    "    \n",
    "    fig,ax = plt.subplots(1,ncols)\n",
    "    ax[0].plot(recall)\n",
    "    ax[0].set_title('Recall')\n",
    "    ax[0].set_xlabel('Word in true list')\n",
    "    ax[0].set_ylabel('Present in recalled list')\n",
    "\n",
    "    ax[1].plot(precision)\n",
    "    ax[1].set_title('Precision')\n",
    "    ax[1].set_xlabel('Word in output (unique)')\n",
    "    ax[1].set_ylabel('Present in true list')\n",
    "\n",
    "    if i_bool:\n",
    "        ax[2].plot(precision_int)\n",
    "        ax[2].set_title('False alarms to interjections')\n",
    "        ax[2].set_xlabel('Word in output (unique)')\n",
    "        ax[2].set_ylabel('Present in interjection')\n",
    "    \n",
    "    if gated:\n",
    "        ax[-2].plot(recall_gated)\n",
    "        ax[-2].set_title('Gated recall')\n",
    "        ax[-2].set_xlabel('Word in GATED true list (abcdefgh)')\n",
    "        ax[-2].set_ylabel('Present in recalled list')\n",
    "\n",
    "        ax[-1].plot(precision_gated)\n",
    "        ax[-1].set_title('Gated precision')\n",
    "        ax[-1].set_xlabel('Word in output (unique)')\n",
    "        ax[-1].set_ylabel('Present in GATED true list (abcdefgh)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5412e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = subsample_words(all_words, list_length*2, seed=0)\n",
    "first_words = words[:list_length]\n",
    "second_words = words[list_length:]\n",
    "pairs = make_pairs(first_words, second_words)\n",
    "\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(len(pairs)) \n",
    "shuffled_first_words = [first_words[i] for i in perm]\n",
    "targets = [second_words[i] for i in perm]\n",
    "\n",
    "interjection_words = subsample_words(all_words, interjection_length*2, seed=0, avoid=words)\n",
    "interjection_pairs = make_pairs(interjection_words[:interjection_length], interjection_words[interjection_length:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81275ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_inp = make_inp(\n",
    "    pairs, shuffled_first_words,\n",
    "    preamble = \"Here is a list of word pairs:\",\n",
    "    cue = \"Now we'll begin the memory test. Here is a list of words, one from each pair, in random order \" \\\n",
    "        \"Please output a list of corresponding word pairs from the studied list. \" \\\n",
    "        \"Do not think step by step, only output the list of words. Here are the test words: \"\n",
    ")\n",
    "print(pa_inp)\n",
    "\n",
    "pa_inp_informed = make_inp(\n",
    "    pairs, shuffled_first_words,\n",
    "    preamble = \"Here is a list of word pairs. After seeing this list, you will be tested on your memory for the pairs:\",\n",
    "    cue = \"Now we'll begin the memory test. Here is a list of words, one from each pair, in random order. \" \\\n",
    "        \"Please output a list of corresponding word pairs from the studied list. \" \\\n",
    "        \"Do not think step by step, only output the list of words. Here are the test words: \"\n",
    ")\n",
    "print(pa_inp_informed)\n",
    "\n",
    "pa_inp_interjection = make_inp(\n",
    "    pairs, shuffled_first_words,\n",
    "    preamble = \"Here is a list of word pairs:\",\n",
    "    cue = \"Now we'll begin the memory test. Here is a list of words, one from each pair in the original list, in random order. \" \\\n",
    "        \"Please output a list of corresponding word pairs from the studied list. \" \\\n",
    "        \"Do not think step by step, only output the list of words. Here are the test words:\",\n",
    "    interjection = \"You will now see another list of word pairs:\",\n",
    "    interjection_words = interjection_pairs,\n",
    ")\n",
    "print(pa_inp_interjection)\n",
    "\n",
    "pa_inp_interjection_informed = make_inp(\n",
    "    pairs, shuffled_first_words,\n",
    "    preamble = \"Here is a list of word pairs. After seeing this list, you will see another list of pairs, and then be tested on your memory for these original pairs:\",\n",
    "    cue = \"Now we'll begin the memory test. Here is a list of words, one from each pair in the original list, in random order. \" \\\n",
    "        \"Please output a list of corresponding word pairs from the studied list. \" \\\n",
    "        \"Do not think step by step, only output the list of words. Here are the test words:\",\n",
    "    interjection = \"You will now see another list of word pairs. Later, in the memory test, you should not base your responses on the pairs in this list:\",\n",
    "    interjection_words = interjection_pairs,\n",
    ")\n",
    "print(pa_inp_interjection_informed)\n",
    "\n",
    "pa_inp_gated = make_inp(\n",
    "    pairs, shuffled_first_words,\n",
    "    preamble = \"Here is a list of word pairs:\",\n",
    "    cue = \"Now we'll begin the memory test. Here is a list of words, one from each pair in the original list, in random order. \" \\\n",
    "        \"Please output a list of each word's pair in the studied list, but ONLY for words whose pair (second word) starts with a,b,c,d,e,f,g, or h. \" \\\n",
    "        \"Do not think step by step, only output the list of words. Here are the test words:\",\n",
    ")\n",
    "print(pa_inp_gated)\n",
    "\n",
    "pa_inp_gated_informed = make_inp(\n",
    "    pairs, shuffled_first_words,\n",
    "    preamble = \"Here is a list of word pairs. After seeing this list, you will see another list of pairs, and then \" \\\n",
    "        \"be tested on your memory ONLY for the pairs where the SECOND word starts with a,b,c,d,e,f,g, and h.\",\n",
    "    cue = \"Now we'll begin the memory test. Here is a list of words, one from each pair in the original list, in random order. \" \\\n",
    "        \"Please output a list of each word's pair in the studied list, but ONLY for words whose pair (second word) starts with a,b,c,d,e,f,g, or h. \" \\\n",
    "        \"Do not think step by step, only output the list of words. Here are the test words:\",\n",
    ")\n",
    "print(pa_inp_gated_informed)\n",
    "\n",
    "pa_inp_gated_informed_interjection = make_inp(\n",
    "    pairs, shuffled_first_words,\n",
    "    preamble = \"Here is a list of word pairs. After seeing this list, you will see another list of pairs, and then \" \\\n",
    "        \"be tested on your memory ONLY for the pairs where the SECOND word starts with a,b,c,d,e,f,g, and h.\",\n",
    "    cue = \"Now we'll begin the memory test. Here is a list of words, one from each pair in the original list, in random order. \" \\\n",
    "        \"Please output a list of each word's pair in the studied list, but ONLY for words whose pair (second word) starts with a,b,c,d,e,f,g, or h. \" \\\n",
    "        \"Do not think step by step, only output the list of words. Here are the test words:\",\n",
    "    interjection = \"You will now see another list of words. Later, in the memory test, you should not base your responses on the pairs in this list:\",\n",
    "    interjection_words = interjection_pairs,\n",
    "\n",
    ")\n",
    "print(pa_inp_gated_informed_interjection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64fc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp in [pa_inp, pa_inp_informed, pa_inp_interjection, pa_inp_interjection]:\n",
    "    print(inp)\n",
    "    output = query_model(pipe, inp)\n",
    "    plot_results(targets, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp in [pa_inp, pa_inp_informed, pa_inp_interjection, pa_inp_interjection]:\n",
    "    print(inp)\n",
    "    output = query_model(pipe, inp)\n",
    "    print(output)\n",
    "    plot_results(targets, output, gated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902341d",
   "metadata": {},
   "source": [
    "# 4. Paired associate inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce225b80",
   "metadata": {},
   "source": [
    "Learn: a-b, b-c\n",
    "\n",
    "Test: a vs c/d?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ecf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_length = 50\n",
    "list_length = round(list_length/3)*3 # make into closest multiple of 3\n",
    "interjection_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d72db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(target_words, lure_words, output_words, interjected_list=[]):\n",
    "    recall = [w in output_words for w in target_words]\n",
    "    precision = [w in set(target_words) for w in np.unique(output_words)]\n",
    "    precision_lure = [w in set(lure_words) for w in np.unique(output_words)]\n",
    "    precision_int = [w in set(interjected_list) for w in np.unique(output_words)]\n",
    "    \n",
    "    ncols = 3 if len(interjected_list) == 0 else 4\n",
    "    fig,ax = plt.subplots(1,ncols)\n",
    "    ax[0].plot(recall)\n",
    "    ax[0].set_title('Recall')\n",
    "    ax[0].set_xlabel('Word in true list')\n",
    "    ax[0].set_ylabel('Present in recalled list')\n",
    "\n",
    "    ax[1].plot(precision)\n",
    "    ax[1].set_title('Precision')\n",
    "    ax[1].set_xlabel('Word in output (unique)')\n",
    "    ax[1].set_ylabel('Present in TRUE list')\n",
    "\n",
    "    ax[2].plot(precision_lure)\n",
    "    ax[2].set_title('Lure precision')\n",
    "    ax[2].set_xlabel('Word in output (unique)')\n",
    "    ax[2].set_ylabel('Present in LURE list')\n",
    "\n",
    "    if len(interjected_list) > 0:\n",
    "        ax[3].plot(precision_int)\n",
    "        ax[3].set_title('Interjection precision')\n",
    "        ax[3].set_xlabel('Word in output (unique)')\n",
    "        ax[3].set_ylabel('Present in INTERJECTION list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials are either a->b, b->c, or d->e\n",
    "# 1/3 of trials have d, 1/3 have e, 1/3 a, 1/3 c, 2/3 b\n",
    "words = subsample_words(all_words, list_length*2, seed=0)\n",
    "a_words = words[:int(list_length/3)]\n",
    "b_words = words[int(list_length/3):list_length]\n",
    "c_words = words[list_length:int(4/3*list_length)]\n",
    "d_words = words[int(4/3*list_length):int(5/3*list_length)]\n",
    "e_words = words[int(5/3*list_length):]\n",
    "\n",
    "ab_pairs = make_pairs(a_words, b_words) # 1/3 of trials\n",
    "bc_pairs = make_pairs(b_words, c_words) # 1/3 of trials\n",
    "de_pairs = make_pairs(d_words, e_words) # 1/3 of trials\n",
    "\n",
    "# need to see the AB pairs before the BC, but the DE can come anywhere\n",
    "training_pairs = make_training_order(ab_pairs, bc_pairs, de_pairs)\n",
    "test_probes, targets, lures = make_test_probes(cue_words = a_words, target_words = c_words, lure_words = e_words)\n",
    "\n",
    "interjection_words = subsample_words(all_words, interjection_length*2, seed=0, avoid=words)\n",
    "interjection_pairs = make_pairs(interjection_words[:interjection_length], interjection_words[interjection_length:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pai_inp = make_inp(\n",
    "    training_pairs, test_probes,\n",
    "    preamble = \"Here is a list of word pairs:\",\n",
    "    cue = \"Now we'll begin the test. \" \\\n",
    "        \"Here is a list of test probes; each one contains a CUE word, from the original list, and two possible TARGETS. \" \\\n",
    "        \"Select a target based on the associations learned in the original list. \" \\\n",
    "        \"Please output a list of your chosen targets (one of the two target words, for each cue in the list); do not respond with any word that is not one of the possible targets. \" \\\n",
    "        \"Do not think step by step, only output the list of chosen targets. Here are the test words:\",\n",
    ")\n",
    "print(pai_inp)\n",
    "\n",
    "pai_inp_informed = make_inp(\n",
    "    training_pairs, test_probes,\n",
    "    preamble = \"Here is a list of word pairs. \" \\\n",
    "        \"After seeing this list, you will be tested on inferential associations between words in this list. \" \\\n",
    "        \"Here are the word pairs:\",\n",
    "    cue = \"Now we'll begin the test. Here is a list of test probes; each one contains a CUE word, from the original list, and two possible TARGETS. \" \\\n",
    "        \"Select a target based on the associations learned in the original list. \" \\\n",
    "        \"Please output a list of your chosen targets (one of the two target words, for each cue in the list); do not respond with any word that is not one of the possible targets. \" \\\n",
    "        \"Do not think step by step, only output the list of chosen targets. Here are the test words:\",\n",
    ")\n",
    "print(pai_inp_informed)\n",
    "\n",
    "pai_inp_informed_interjected = make_inp(\n",
    "    training_pairs, test_probes,\n",
    "    preamble = \"Here is a list of word pairs. After seeing this list, you will see another list of pairs. \" \\\n",
    "        \"Then, you will be tested on inferential associations between words in this original list of pairs. \" \\\n",
    "        \"Here are the word pairs:\",\n",
    "    cue = \"Now we'll begin the test. \" \\\n",
    "        \"Here is a list of test probes; each one contains a CUE word, from the original list, and two possible TARGETS. \" \\\n",
    "        \"Select a target based on the associations learned in the original list. \" \\\n",
    "        \"Please output a list of your chosen targets (one of the two target words, for each cue in the list); do not respond with any word that is not one of the possible targets. \" \\\n",
    "        \"Do not think step by step, only output the list of chosen targets. Here are the test words:\",\n",
    "    interjection = \"You will now see another list of word pairs. Later, during the test, you should not base your responses on the pairs in this list:\",\n",
    "    interjection_words = interjection_pairs,\n",
    ")\n",
    "print(pai_inp_informed_interjected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cdcaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp in [pai_inp, pai_inp_informed, pai_inp_informed_interjected]:\n",
    "    print(inp)\n",
    "    output = query_model(pipe, inp)\n",
    "    print(output)\n",
    "    plot_results(targets, lures, output, interjection_words) # C are targets, E are lures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa230a74",
   "metadata": {},
   "source": [
    "# 5. Acquired equivalence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233fef9",
   "metadata": {},
   "source": [
    "\n",
    "a -> b\n",
    "\n",
    "c -> b\n",
    "\n",
    "a -> d\n",
    "\n",
    "c -> ? d or e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ffd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_length = 50\n",
    "list_length = round(list_length/4)*4 # make into closest multiple of 4\n",
    "interjection_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c44c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(target_words, lure_words, output_words, interjected_list=[]):\n",
    "    recall = [w in output_words for w in target_words]\n",
    "    precision = [w in set(target_words) for w in np.unique(output_words)]\n",
    "    precision_lure = [w in set(lure_words) for w in np.unique(output_words)]\n",
    "    precision_int = [w in set(interjected_list) for w in np.unique(output_words)]\n",
    "    \n",
    "    ncols = 3 if len(interjected_list) == 0 else 4\n",
    "    fig,ax = plt.subplots(1,ncols)\n",
    "    ax[0].plot(recall)\n",
    "    ax[0].set_title('Recall')\n",
    "    ax[0].set_xlabel('Word in true list')\n",
    "    ax[0].set_ylabel('Present in recalled list')\n",
    "\n",
    "    ax[1].plot(precision)\n",
    "    ax[1].set_title('Precision')\n",
    "    ax[1].set_xlabel('Word in output (unique)')\n",
    "    ax[1].set_ylabel('Present in TRUE list')\n",
    "\n",
    "    ax[2].plot(precision_lure)\n",
    "    ax[2].set_title('Lure precision')\n",
    "    ax[2].set_xlabel('Word in output (unique)')\n",
    "    ax[2].set_ylabel('Present in LURE list')\n",
    "\n",
    "    if len(interjected_list) > 0:\n",
    "        ax[3].plot(precision_int)\n",
    "        ax[3].set_title('Interjection precision')\n",
    "        ax[3].set_xlabel('Word in output (unique)')\n",
    "        ax[3].set_ylabel('Present in INTERJECTION list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28808fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = subsample_words(all_words, list_length*3) \n",
    "a_words = words[:int(list_length/2)]\n",
    "c_words = words[int(list_length/2):list_length]\n",
    "b_words = words[list_length:int(list_length*2)] # all will have a b-word\n",
    "d_words = words[int(list_length*2):]\n",
    "\n",
    "ab_pairs = make_pairs(a_words, b_words) # 1/3 of trials\n",
    "cb_pairs = make_pairs(c_words,b_words) # 1/3 of trials\n",
    "\n",
    "training_pairs = make_training_order(ab_pairs, cb_pairs)\n",
    "ad_pairs = make_pairs(a_words, d_words)\n",
    "training_pairs = [training_pairs, ad_pairs]\n",
    "\n",
    "d_shuffled_lures = generate_derangement(d_words)\n",
    "test_probes, targets, lures = make_test_probes(cue_words = a_words, target_words = c_words, lure_words = d_shuffled_lures)\n",
    "\n",
    "interjection_words = subsample_words(all_words, interjection_length*2, seed=0, avoid=words)\n",
    "interjection_pairs = make_pairs(interjection_words[:interjection_length], interjection_words[interjection_length:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94788e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_inp = make_inp(\n",
    "    training_pairs, test_probes,\n",
    "    preamble = \"Here is a list of word pairs:\",\n",
    "    cue = \"Now we'll begin the test. \" \\\n",
    "        \"Here is a list of test probes; each one contains a CUE word, and two possible TARGETS. \" \\\n",
    "        \"Select a target based on the associations you've learned in the original list. \" \\\n",
    "        \"Please output a list of your chosen targets (one of the two target words, for each cue in the list); do not respond with any word that is not one of the possible targets. \" \\\n",
    "        \"Do not think step by step, only output the list of chosen targets. Here are the test words:\",\n",
    ")\n",
    "print(ae_inp)\n",
    "\n",
    "ae_inp_informed = make_inp(\n",
    "    training_pairs, test_probes,\n",
    "    preamble = \"Here is a list of word pairs. \" \\\n",
    "        \"After seeing this list, you will be tested on inferential associations between words in this list. \" \\\n",
    "        \"Here are the word pairs:\",\n",
    "    cue = \"Now we'll begin the test. \" \\\n",
    "        \"Here is a list of test probes; each one contains a CUE word, from the original list, and two possible TARGETS. \" \\\n",
    "        \"Select a target based on the associations you've learned. \" \\\n",
    "        \"Please output a list of your chosen targets (one of the two target words, for each cue in the list); do not respond with any word that is not one of the possible targets. \" \\\n",
    "        \"Do not think step by step, only output the list of chosen targets. Here are the test words:\",\n",
    ")\n",
    "print(ae_inp_informed)\n",
    "\n",
    "ae_inp_informed_interjected = make_inp(\n",
    "    training_pairs, test_probes,\n",
    "    preamble = \"Here is a list of word pairs. \" \\\n",
    "        \"After seeing this list, you will see another list of pairs. \" \\\n",
    "        \"Then, you will be tested on inferential associations between words in this list. \" \\\n",
    "        \"Here are the word pairs:\",\n",
    "    cue = \"Now we'll begin the test. \" \\\n",
    "        \"Here is a list of test probes; each one contains a CUE word, from the original list, and two possible TARGETS. \" \\\n",
    "        \"Select a target based on the associations you've learned. \" \\\n",
    "        \"Please output a list of your chosen targets (one of the two target words, for each cue in the list); do not respond with any word that is not one of the possible targets. \" \\\n",
    "        \"Do not think step by step, only output the list of chosen targets. Here are the test words:\",\n",
    "    interjection = \"You will now see another list of word pairs. Later, during the test, you should not base your responses on the pairs in this list:\",\n",
    "    interjection_words = interjection_pairs,\n",
    ")\n",
    "print(ae_inp_informed_interjected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179db510",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp in [ae_inp, ae_inp_informed, ae_inp_informed_interjected]:\n",
    "    print(inp)\n",
    "    output = query_model(pipe, inp)\n",
    "    print(output)\n",
    "    plot_results(targets, lures, output, interjection_words) # C are targets, E are lures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe22026",
   "metadata": {},
   "source": [
    "# 6. Transitive inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6130bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitive_chain_length = 10 # A > B > C > D > E ...\n",
    "interjection_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transitive_inference_probes(words):\n",
    "    np.random.seed(0)\n",
    "    bigger, smaller = [],[]\n",
    "    count = 0\n",
    "    for i in range(transitive_chain_length):\n",
    "        for j in range(i + 2, transitive_chain_length):  # skip adjacent pairs\n",
    "            bigger.append(words[i])\n",
    "            smaller.append(words[j])\n",
    "            count += 1\n",
    "    perm = np.random.permutation(count)\n",
    "    bigger = [bigger[p] for p in perm]\n",
    "    smaller = [smaller[p] for p in perm]\n",
    "    test_probes = make_pairs(bigger, smaller, joiner = \"?\", randomize=True) # B ? E\n",
    "    return test_probes, bigger, smaller\n",
    "\n",
    "\n",
    "def plot_results(bigger, smaller, output, distance=[]):\n",
    "    bigger = np.array(bigger)\n",
    "    smaller = np.array(smaller)\n",
    "    output = np.array(output)\n",
    "\n",
    "    correct = np.mean([output[i] == bigger[i] for i in range(len(output))])\n",
    "    incorrect = np.mean([output[i] == smaller[i] for i in range(len(output))])\n",
    "    random = np.mean([output[i] != bigger[i] and output[i] != smaller[i]  for i in range(len(output))])\n",
    "\n",
    "    n_cols=1\n",
    "    if len(distance) > 0:\n",
    "        n_cols=2\n",
    "        dist_x,dist_y=[],[]\n",
    "        for dist in sorted(np.unique(distance)):\n",
    "            dist_mask = np.array(distance) == dist\n",
    "            dist_correct = np.mean([output[dist_mask][i] == bigger[dist_mask][i] for i in range(sum(dist_mask))])\n",
    "            dist_x.append(dist)\n",
    "            dist_y.append(dist_correct)\n",
    "\n",
    "    fig,ax = plt.subplots(1,n_cols)\n",
    "    ax = np.atleast_1d(ax)  # ensures ax is always indexable\n",
    "    ax[0].bar([1,2,3], [correct,incorrect,random])\n",
    "    ax[0].set_xticks([1,2,3], labels=['Correct','Incorrect','Random response'], rotation=30)\n",
    "    ax[0].set_ylabel('%')\n",
    "    ax[0].set_ylim(0,1)\n",
    "\n",
    "    if len(distance) > 0:\n",
    "        ax[1].plot(dist_x,dist_y)\n",
    "        ax[1].set_xlabel('Distance in transitive chain')\n",
    "        ax[1].set_ylabel('Accuracy')\n",
    "        ax[1].set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf15795",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = subsample_words(all_words, transitive_chain_length, seed=0) # each stimulus is one word in the chain\n",
    "\n",
    "adjacent_pairs = make_pairs(words[:-1], words[1:], joiner = '>') # pair up in chain\n",
    "random.seed(0)\n",
    "random.shuffle(adjacent_pairs)\n",
    "\n",
    "test_probes, bigger, smaller = make_transitive_inference_probes(words) # query on pairs of words at least 1 link away\n",
    "\n",
    "interjection_words = subsample_words(all_words, interjection_length*2, seed=0, avoid=words)\n",
    "interjection_pairs = make_pairs(interjection_words[:interjection_length], \n",
    "                                interjection_words[interjection_length:],\n",
    "                                joiner = '>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ae258",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_inp = make_inp(\n",
    "    adjacent_pairs, test_probes,\n",
    "    preamble = \"Here is a list of relations between words:\",\n",
    "    cue = \"Now we'll begin the test. \" \\\n",
    "        \"Here is a list of test probes; each one has two target words from the original set with a ? in between. \" \\\n",
    "        \"Your task is to select the bigger word (>). \" \\\n",
    "        \"Please output a list of your chosen bigger targets (one for each in the list of probes). Do not respond with any word that is not one of the possible targets. \" \\\n",
    "        \"Do not think step by step, only output the list of chosen targets. Here are the test probes:\",\n",
    ")\n",
    "print(ti_inp)\n",
    "\n",
    "ti_inp_informed = make_inp(\n",
    "    adjacent_pairs, test_probes,\n",
    "    preamble = \"Here is a list of relations between words. \" \\\n",
    "        \"After seeing this list, you will be tested on inferential relations between words in this original set. \" \\\n",
    "        \"Here are the word relations:\",\n",
    "    cue = \"Now we'll begin the test. \" \\\n",
    "        \"Here is a list of test probes; each one has two target words from the original set with a ? in between. \" \\\n",
    "        \"Your task is to select the bigger word (>). \" \\\n",
    "        \"Please output a list of your chosen bigger targets (one for each in the list of probes). Do not respond with any word that is not one of the possible targets. \" \\\n",
    "        \"Do not think step by step, only output the list of chosen targets. Here are the test probes:\",\n",
    ")\n",
    "print(ti_inp_informed)\n",
    "\n",
    "ti_inp_informed_interjected = make_inp(\n",
    "    adjacent_pairs, test_probes,\n",
    "    preamble = \"Here is a list of relations between words. \" \\\n",
    "        \"After seeing this list, you will see another list of relations. \" \\\n",
    "        \"Then, you will be tested on inferential relations between words in this original set. \" \\\n",
    "        \"Here are the word relations:\",\n",
    "    cue = \"Now we'll begin the test. \" \\\n",
    "        \"Here is a list of test probes; each one has two target words from the original set with a ? in between. \" \\\n",
    "         \"Your task is to select the bigger word (>). \" \\\n",
    "        \"Please output a list of your chosen bigger targets (one for each in the list of probes). Do not respond with any word that is not one of the possible targets. \" \\\n",
    "        \"Do not think step by step, only output the list of chosen targets. Here are the test probes:\",\n",
    "    interjection = \"You will now see another list of word relations. Later, during the test, you should not base your responses on the relations or words in this list:\",\n",
    "    interjection_words = interjection_pairs,\n",
    ")\n",
    "print(ti_inp_informed_interjected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8960a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp in [ti_inp, ti_inp_informed, ti_inp_informed_interjected]:\n",
    "    print(inp)\n",
    "    output = query_model(pipe, inp)\n",
    "    print(output)\n",
    "    plot_results(bigger, smaller, output, interjection_words) # C are targets, E are lures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
